{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import psycopg2\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "aws_key = config.get('AWS','KEY')\n",
    "aws_secret = config.get('AWS','SECRET')\n",
    "arn_role = config.get('IAM_ROLE','role_name')\n",
    "dwh_cluster_type = config.get('CLUSTER', 'dwh_cluster_type')\n",
    "dwh_num_nodes = config.get('CLUSTER', 'dwh_num_nodes')\n",
    "dwh_node_type = config.get('CLUSTER', 'dwh_node_type')\n",
    "dwh_cluster = config.get('CLUSTER','dwh_cluster')\n",
    "db_name = config.get('CLUSTER','db_name')\n",
    "db_user = config.get('CLUSTER','db_user')\n",
    "db_password = config.get('CLUSTER','db_password')\n",
    "db_port = config.get('CLUSTER','db_port')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create redshift client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "redshift = boto3.client('redshift'\n",
    "                        , region_name = 'us-west-2'\n",
    "                        , aws_access_key_id = aws_key\n",
    "                        , aws_secret_access_key = aws_secret)\n",
    "\n",
    "iam = boto3.client('iam'\n",
    "                    , region_name = 'us-west-2'\n",
    "                    , aws_access_key_id = aws_key\n",
    "                    , aws_secret_access_key = aws_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create New ARN Role & Attach Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Create the IAM role\n",
    "try:\n",
    "    print('1.1 Creating a new IAM Role')\n",
    "    dwhRole = iam.create_role(\n",
    "          RoleName = arn_role\n",
    "        , Description = 'IAM Role for udacity dwh project, allowing Redshift access to S3 Bucket (ReadOnly)'\n",
    "        , AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "             'Version': '2012-10-17'})\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(\"1.2 Attaching Policy\")\n",
    "\n",
    "iam.attach_role_policy(RoleName=arn_role,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Get Arn from new IAM Role & Write to Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "role_arn = iam.get_role(RoleName=arn_role)['Role']['Arn']\n",
    "\n",
    "# Set value for key in config file \n",
    "config.set('IAM_ROLE', 'ARN', role_arn)\n",
    "\n",
    "# Writing our configuration file to 'dwh.cfg'\n",
    "with open('dwh.cfg', 'w') as configfile:\n",
    "    config.write(configfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create Redshift Cluster\n",
    "- Using client:\n",
    "    - create cluster\n",
    "    - create cluster security group\n",
    "    - create iam role\n",
    "    - attach policy (read s3) to iam role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        #HW\n",
    "        ClusterType=dwh_cluster_type,\n",
    "        NodeType=dwh_node_type,\n",
    "        NumberOfNodes=int(dwh_num_nodes),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName=db_name,\n",
    "        ClusterIdentifier=dwh_cluster,\n",
    "        MasterUsername=db_user,\n",
    "        MasterUserPassword=db_password,\n",
    "        \n",
    "        #Roles (for s3 access)\n",
    "        IamRoles=[role_arn]  \n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%run create_cluster.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%run delete_cluster.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create Staging Table & Load data from s3 bucket\n",
    "\n",
    "- Create cluster\n",
    "- Log in using psycopg2 credentials from config file\n",
    "- Write 'Create table statement' & execute query using psycopg2 cursor\n",
    "\n",
    "\n",
    "#### S3 Song Dataset\n",
    "\n",
    "- s3://udacity-dend/song_data\n",
    "- Example data:\n",
    "{ \"num_songs\": 1\n",
    " , \"artist_id\": \"ARJIE2Y1187B994AB7\"\n",
    " , \"artist_latitude\": null\n",
    " , \"artist_longitude\": null\n",
    " , \"artist_location\": \"\"\n",
    " , \"artist_name\": \"Line Renaud\"\n",
    " , \"song_id\": \"SOUPIRU12A6D4FA1E1\"\n",
    " , \"title\": \"Der Kleine Dompfaff\"\n",
    " , \"duration\": 152.92036\n",
    " , \"year\": 0\n",
    " }\n",
    "\n",
    "\n",
    "#### S3 Log Dataset\n",
    "- Log data: s3://udacity-dend/log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "conn = psycopg2.connect(user = config.get('CLUSTER', 'db_user')\n",
    "                        , password = config.get('CLUSTER', 'db_password')\n",
    "                        , host = config.get('CLUSTER', 'dwh_host')\n",
    "                        , port = config.get('CLUSTER', 'db_port')\n",
    "                        , database = config.get('CLUSTER', 'db_name')\n",
    "                       )\n",
    "\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query_create_staging_table_song_data = \"\"\"\n",
    "    CREATE TABLE staging_songs (\n",
    "        artist_id VARCHAR,\n",
    "        artist_location VARCHAR,\n",
    "        artist_latitude FLOAT,\n",
    "        artist_longitude FLOAT,\n",
    "        artist_name VARCHAR,\n",
    "        duration FLOAT,\n",
    "        num_songs INT,\n",
    "        song_id VARCHAR,\n",
    "        title VARCHAR,\n",
    "        year INT\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "cur.execute(query_create_staging_table_song_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query_staging_songs_copy = f\"\"\"\n",
    "    COPY staging_songs\n",
    "    FROM {config.get('S3','song_data')}\n",
    "    credentials 'aws_iam_role={config.get('IAM_ROLE','arn')}'\n",
    "    FORMAT AS JSON 'auto';\n",
    "\"\"\"\n",
    "cur.execute(query_staging_songs_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query_staging_events_copy = f\"\"\"\n",
    "    COPY staging_events\n",
    "    FROM {config.get('S3','log_data')}\n",
    "    credentials 'aws_iam_role={config.get('IAM_ROLE','arn')}'\n",
    "    json {config.get('S3','log_jsonpath')};\n",
    "\"\"\"\n",
    "cur.execute(query_staging_events_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"select * from stl_load_errors\", conn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3', region_name = 'us-west-2', aws_access_key_id = aws_key, aws_secret_access_key = aws_secret)\n",
    "s3_bucket_songs = s3.Bucket(\"udacity-dend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songs_staging = pd.read_sql_query(\"select * from staging_songs\", conn)\n",
    "df_songs_staging.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"select * from artists\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%run create_cluster.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%run create_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%run etl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (ClusterNotFound) when calling the DeleteCluster operation: Cluster dwhhostudacityproject not found.\n"
     ]
    }
   ],
   "source": [
    "%run delete_cluster.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sql_queries import staging_events_copy, staging_songs_copy\n",
    "\n",
    "cur.execute(staging_events_copy)\n",
    "cur.execute(staging_songs_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfe = pd.read_sql_query('select * from staging_events', conn)\n",
    "dfs = pd.read_sql_query('select * from staging_songs', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from songplays', conn).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sql_queries import songplay_table_drop, songplay_table_create, songplay_table_insert\n",
    "\n",
    "cur.execute(songplay_table_drop)\n",
    "cur.execute(songplay_table_create)\n",
    "cur.execute(songplay_table_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songplays = pd.read_sql_query('select * from songplays', conn)\n",
    "df_songs = pd.read_sql_query('select * from songs', conn)\n",
    "df_user = pd.read_sql_query('select * from users', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songs.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
