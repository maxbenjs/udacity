{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b87f862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import boto3\n",
    "import psycopg2\n",
    "from helpers.helpers_sql.sql_statements import sql_copy_statements, sql_merge_statements, sql_delete_staging_statments\n",
    "from helpers.helpers_sql.table_params import staging_tables, dim_tables, fact_tables, staging_fact_tables, helper_tables\n",
    "from helpers.helpers_python.database_class import Database\n",
    "from helpers.helpers_python.aws_s3_class import aws_s3\n",
    "from helpers.helpers_python.python_functions import zip_downloader, extract_and_clean_crime_dataset, extract_and_clean_crime_helper_dataset_gdi, extract_and_clean_crime_helper_dataset_population, extract_and_clean_postcode_helper_dataset\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04806e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_transform_crime_dataset():\n",
    "    zip_downloader(input_dir = 'data/uk_crime_data_raw', output_dir = 'data/uk_crime_data')\n",
    "    \n",
    "    input_dir = 'data/uk_crime_data'\n",
    "    input_file_name = 'UK_Police_Street_Crime_2018-10-01_to_2021_09_31.csv'\n",
    "    output_dir = 'data/uk_crime_data'\n",
    "    output_file_name = 'UK_Police_Street_Crime_2018-10-01_to_2021_09_31.csv'\n",
    "    \n",
    "    extract_and_clean_crime_dataset(input_dir, input_file_name, output_dir, output_file_name)\n",
    "    \n",
    "\n",
    "\n",
    "def extract_and_transform_crime_helper_population_dataset():\n",
    "    input_dir = 'data/uk_helper_data_raw'\n",
    "    input_file_name = 'vcregionalgdhibylareordered.xlsx'\n",
    "    output_dir = 'data/uk_helper_data'\n",
    "    output_file_name = 'uk_regional_population_1997_2016.csv'\n",
    "    extract_and_clean_crime_helper_dataset_population(input_dir, input_file_name, output_dir, output_file_name)\n",
    "\n",
    "    \n",
    "\n",
    "def extract_and_transform_crime_helper_gdi_dataset():\n",
    "    input_dir = 'data/uk_helper_data_raw'\n",
    "    input_file_name = 'vcregionalgdhibylareordered.xlsx'\n",
    "    output_dir = 'data/uk_helper_data'\n",
    "    output_file_name = 'uk_regional_gross_disposable_income_1997_2016.csv'\n",
    "    extract_and_clean_crime_helper_dataset_gdi(input_dir, input_file_name, output_dir, output_file_name)\n",
    "\n",
    "\n",
    "def extract_and_transform_postcode_helper_dataset():\n",
    "    input_dir = 'data/uk_postcode_conversion_raw'\n",
    "    input_file_name = 'PCD_OA_LSOA_MSOA_LAD_AUG19_UK_LU.csv'\n",
    "    output_dir = 'data/uk_postcode_conversion'\n",
    "    output_file_name = 'uk_postcode_mapping.csv'\n",
    "    extract_and_clean_postcode_helper_dataset(input_dir, input_file_name, output_dir, output_file_name)\n",
    "    \n",
    "    \n",
    "    \n",
    "def load_data_to_s3(aws_s3_client):\n",
    "    tables = staging_tables + helper_tables\n",
    "    aws_s3_client.upload_multiple_file_to_s3(tables)\n",
    "    \n",
    "\n",
    "\n",
    "def create_dwh_tables(db):\n",
    "    all_table_params = staging_tables + dim_tables + fact_tables + helper_tables + staging_fact_tables\n",
    "    db.create_missing_database_tables(all_table_params)\n",
    "       \n",
    "\n",
    "def load_staging_tables(db, config):\n",
    "    tables = staging_tables\n",
    "\n",
    "    sql_copy_statement = sql_copy_statements[0]\n",
    "    sql_insert_statement = sql_merge_statements[2]\n",
    "\n",
    "    db.load_staging_tables_s3_based(tables, config, sql_copy_statement)\n",
    "    db.load_staging_tables_dwh_based(tables, sql_insert_statement)\n",
    "    \n",
    "    \n",
    "\n",
    "def load_dim_tables(db):\n",
    "    tables = dim_tables\n",
    "    db.load_dim_tables(tables, sql_upsert_statement=sql_merge_statements[3])\n",
    "    \n",
    "    \n",
    "    \n",
    "def load_helper_tables(db, config):\n",
    "    tables = helper_tables\n",
    "    sql_copy_statement = sql_copy_statements[0]\n",
    "    db.load_staging_tables_s3_based(tables, config, sql_copy_statement)\n",
    "    \n",
    "\n",
    "\n",
    "def load_staging_fact_tables(db):\n",
    "    tables = staging_fact_tables\n",
    "    sql_insert_statement = sql_merge_statements[2]\n",
    "    db.load_staging_tables_dwh_based(tables, sql_insert_statement)\n",
    "\n",
    "    \n",
    "\n",
    "def load_fact_tables(db):\n",
    "    tables = fact_tables\n",
    "    sql_upsert_statement = sql_merge_statements[3]\n",
    "    db.load_fact_tables(tables, sql_upsert_statement)\n",
    "    \n",
    "    \n",
    "\n",
    "def delete_data_in_staging_tables(db):\n",
    "    tables = staging_tables + staging_fact_tables\n",
    "    sql_delete_statement = sql_delete_staging_statments[0]\n",
    "    db.delete_staging_data(tables, sql_delete_statement)\n",
    "    \n",
    "        \n",
    "\n",
    "def data_quality_checks(db):\n",
    "    dim_and_fact_tables = dim_tables + fact_tables\n",
    "    db.qa_dim_fact_tables_contain_values(tables=dim_and_fact_tables)\n",
    "    \n",
    "    staging_tables_complete = staging_tables + staging_fact_tables\n",
    "    db.qa_staging_tables_empty(tables=staging_tables_complete)\n",
    "    \n",
    "\n",
    "\n",
    "def delete_s3_files(aws_s3_client):\n",
    "    tables = staging_tables + helper_tables\n",
    "    aws_s3_client.delete_multiple_s3_files(tables)\n",
    "\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    config = configparser.ConfigParser()\n",
    "    config.read_file(open('dl.cfg'))\n",
    "    \n",
    "    aws_access_key_id = config['AWS']['key'] \n",
    "    aws_secret_access_key = config['AWS']['secret']\n",
    "    host = config['REDSHIFT_CLUSTER']['db_host']\n",
    "    port = config['REDSHIFT_CLUSTER']['db_port']\n",
    "    dbname = config['REDSHIFT_CLUSTER']['db_name']\n",
    "    user = config['REDSHIFT_CLUSTER']['db_user']\n",
    "    password = config['REDSHIFT_CLUSTER']['db_password']\n",
    "    \n",
    "    db = Database(host, dbname, port, user, password)\n",
    "    db.connect()    \n",
    "    aws_s3_client = aws_s3(aws_access_key_id, aws_secret_access_key)\n",
    "    \n",
    "    try:\n",
    "        extract_and_transform_crime_dataset()\n",
    "        extract_and_transform_crime_helper_gdi_dataset()\n",
    "        extract_and_transform_crime_helper_population_dataset()\n",
    "        extract_and_transform_postcode_helper_dataset()\n",
    "        #load_data_to_s3(aws_s3_client)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    #try:\n",
    "        #create_dwh_tables(db)\n",
    "        #load_staging_tables(db, config)\n",
    "        #load_dim_tables(db)\n",
    "        #load_helper_tables(db,config)\n",
    "        #load_staging_fact_tables(db)\n",
    "        #load_fact_tables(db)\n",
    "        #delete_data_in_staging_tables(db)\n",
    "        #data_quality_checks(db)\n",
    "        #delete_s3_files(aws_s3_client)\n",
    "    #except Exception as e:\n",
    "    #    print(e)        \n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_seconds = (end_time - start_time)\n",
    "    run_duration = str(timedelta(seconds=elapsed_seconds))\n",
    "    print(f'ETL finished. Runtime: {run_duration}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d18497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           Crime ID    Month  \\\n",
      "0           0  c7000c41002f19263d4adec66b911f1c3f5e7eeb1302a3...  2020-01   \n",
      "1           1  b8bc1b6cf423a9431734982fffb11f803cf82140702cc7...  2020-01   \n",
      "2           2  8c69cefea36edafe5fa3f992ccc31d3cfd0c9af9a81429...  2020-01   \n",
      "\n",
      "             Reported by           Falls within  Longitude   Latitude  \\\n",
      "0  West Yorkshire Police  West Yorkshire Police  -1.570572  53.607792   \n",
      "1  West Yorkshire Police  West Yorkshire Police  -1.670108  53.553629   \n",
      "2  West Yorkshire Police  West Yorkshire Police  -1.879031  53.943807   \n",
      "\n",
      "                       Location  LSOA code      LSOA name     Crime type  \\\n",
      "0    On or near Park/Open Space  E01007418  Barnsley 016A    Other theft   \n",
      "1  On or near Huddersfield Road  E01007426  Barnsley 027D        Robbery   \n",
      "2     On or near Cross End Fold  E01010646  Bradford 001A  Bicycle theft   \n",
      "\n",
      "                           Last outcome category  Context  \n",
      "0                      Status update unavailable      NaN  \n",
      "1  Investigation complete; no suspect identified      NaN  \n",
      "2  Investigation complete; no suspect identified      NaN  \n",
      "Extracted and transformed crime dataset: UK_Police_Street_Crime_2018-10-01_to_2021_09_31.csv\n",
      "[Errno 2] No such file or directory: '/Users/maxschlafli/Documents/GitHub/udacity/data_engineering_nano_degree/5_capstone_project/data/uk_helper_data/uk_regional_gross_disposable_income_1997_2016.csv'\n",
      "Extracted and transformed population dataset: uk_regional_population_1997_2016.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/b094yk5s25732_nx3cbjlg7w0000gn/T/ipykernel_35219/2785542791.py:35: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  extract_and_clean_postcode_helper_dataset(input_dir, input_file_name, output_dir, output_file_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted and transformed postcode helper dataset: PCD_OA_LSOA_MSOA_LAD_AUG19_UK_LU.csv\n",
      "ETL finished. Runtime: 0:00:46.723527\n"
     ]
    }
   ],
   "source": [
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ETL.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c406b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
